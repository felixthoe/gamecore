{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Run Analysis\n",
    "\n",
    "This notebook analyzes the results of an experiment run with `SweepRunner`.\n",
    "It loads sweep-level and trial-level results from `data/<experiment_name>`, including sweep parameters and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.insert(0, root_path)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "experiment_name = \"tutorial_sweep_runner\"\n",
    "\n",
    "# If you want the statistics with specific outcomes excluded, you can set this list.\n",
    "exclude_outcomes = [] # [\"exception\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate all sweep result folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = os.path.join(\"..\", \"data\", experiment_name)\n",
    "assert os.path.isdir(experiment_dir), f\"Directory not found: {experiment_dir}\"\n",
    "sweep_dirs = sorted([d for d in glob(os.path.join(experiment_dir, \"sweeps\", \"sweep_*\")) if os.path.isdir(d)])\n",
    "print(f\"Found {len(sweep_dirs)} sweeps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all sweep parameters and trial outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_stats_path = os.path.join(experiment_dir, \"aggregated_stats.json\")\n",
    "if not os.path.exists(aggregated_stats_path):\n",
    "    aggregated_stats_path = os.path.join(experiment_dir, \"aggregated_stats_interim.json\")\n",
    "    if not os.path.exists(aggregated_stats_path):\n",
    "        raise FileNotFoundError(f\"Aggregated stats file not found: Neither {os.path.join(experiment_dir, \"aggregated_stats.json\")} nor {os.path.join(experiment_dir, \"aggregated_stats_interim.json\")}\")\n",
    "with open(aggregated_stats_path, \"r\") as f:\n",
    "    aggregated_stats = json.load(f)\n",
    "trial_kwargs = aggregated_stats[\"trial_kwargs\"]\n",
    "\n",
    "sweep_records = []\n",
    "trial_records = []\n",
    "n_trials_list = []\n",
    "for sweep_dir in sweep_dirs:\n",
    "    params_path = os.path.join(sweep_dir, \"params.json\")\n",
    "    result_path = os.path.join(sweep_dir, \"result.json\")\n",
    "    if not (os.path.exists(params_path) and os.path.exists(result_path)):\n",
    "        continue\n",
    "    with open(params_path, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    with open(result_path, \"r\") as f:\n",
    "        result = json.load(f)\n",
    "    # Sweep-level record\n",
    "    sweep_record = {\n",
    "        k: (str(v) if isinstance(v, (list, dict)) else v)\n",
    "        for k, v in params.items()\n",
    "    }\n",
    "    sweep_record.update({\n",
    "        \"sweep_dir\": sweep_dir,\n",
    "        \"stats_abs\": result.get(\"stats_abs\", {}),\n",
    "        \"stats_rel\": result.get(\"stats_rel\", {}),\n",
    "        \"duration_stats\": result.get(\"duration_stats\", {}),\n",
    "        \"timestamp\": result.get(\"timestamp\", None)\n",
    "    })\n",
    "    n_trials = len(result.get(\"trial_outcomes\", []))\n",
    "    sweep_record[\"n_trials\"] = n_trials\n",
    "    n_trials_list.append(n_trials)\n",
    "    sweep_records.append(sweep_record)\n",
    "    # Trial-level records\n",
    "    for trial in result.get(\"trial_outcomes\", []):\n",
    "        rec = dict(params)\n",
    "        rec.update(trial)\n",
    "        rec[\"sweep_dir\"] = sweep_dir\n",
    "        trial_records.append(rec)\n",
    "\n",
    "df_sweeps = pd.DataFrame(sweep_records)\n",
    "df_trials = pd.DataFrame(trial_records)\n",
    "if exclude_outcomes:\n",
    "    df_trials = df_trials[~df_trials[\"outcome\"].isin(exclude_outcomes)].copy()\n",
    "print(f\"Loaded {len(df_sweeps)} sweeps and {len(df_trials)} trials.\")\n",
    "non_param_cols = [\"sweep_dir\", \"stats_abs\", \"stats_rel\", \"duration_stats\", \"timestamp\", \"n_trials\"]\n",
    "param_cols = [c for c in df_sweeps.columns if c not in non_param_cols]\n",
    "trial_non_param_cols = {\"seed\", \"outcome\", \"duration\", \"trial\", \"sweep_dir\", \"exception\", \"traceback\"}\n",
    "trial_param_cols = [c for c in df_trials.columns if c not in trial_non_param_cols]\n",
    "\n",
    "outcome_df = pd.DataFrame(df_sweeps[\"stats_abs\"].tolist()).fillna(0).astype(int)\n",
    "# Remove excluded outcomes\n",
    "if exclude_outcomes:\n",
    "    exclude_outcomes = [outcome for outcome in exclude_outcomes if outcome in outcome_df.columns]\n",
    "    if len(exclude_outcomes) > 0:\n",
    "        print(f\"We will exclude outcomes: {exclude_outcomes}\")\n",
    "        outcome_df = outcome_df.drop(columns=exclude_outcomes, errors='ignore')\n",
    "# Compute relative frequencies based on remaining outcomes\n",
    "n_trials_eff = outcome_df.sum(axis=1)\n",
    "outcome_df = outcome_df.div(n_trials_eff, axis=0) * 100\n",
    "\n",
    "# Check if all sweeps have the same number of trials\n",
    "if len(set(n_trials_list)) > 1:\n",
    "    print(\"âš ï¸ Warning: Not all sweeps have the same number of trials! (corrupted data?)\")\n",
    "else:\n",
    "    print(f\"All sweeps have {n_trials_list[0]} trials.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of sweep parameters and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique values for each sweep parameter\n",
    "print(\"Unique parameter values across all sweeps:\")\n",
    "for col in param_cols:\n",
    "    uniques = df_sweeps[col].unique()\n",
    "    print(f\"- {col}: {uniques}\")\n",
    "\n",
    "print(f\"\\nAppearing outcomes: {outcome_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"exception\" in df_trials.columns:\n",
    "    df_exceptions = df_trials.dropna(subset=[\"exception\"]).copy()\n",
    "\n",
    "    if not df_exceptions.empty:\n",
    "        exception_counts = (\n",
    "            df_exceptions[\"exception\"]\n",
    "            .value_counts()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"exception\": \"message\"})\n",
    "        )\n",
    "\n",
    "        limit_exception_prints = 10\n",
    "        print(f\"=== First {limit_exception_prints} Exceptions ===\\n\")\n",
    "        exception_count = 0\n",
    "        for msg, count in zip(exception_counts[\"message\"], exception_counts[\"count\"]):\n",
    "            short_msg = msg.replace(\"\\n\", \" \")[:100] + (\"...\" if len(msg) > 100 else \"\")\n",
    "            print(f\"{count} Ã— {short_msg}\")\n",
    "            exception_count += 1\n",
    "            if exception_count >= limit_exception_prints:\n",
    "                break\n",
    "                # pass\n",
    "\n",
    "        # Have a look at the traceback of specific exception type\n",
    "        exception_filter = \"Q_\"  # paste part of the exception string here\n",
    "        limit_traceback_prints = 1\n",
    "        df_filtered = df_exceptions[df_exceptions[\"exception\"].str.contains(exception_filter, regex=False)]\n",
    "\n",
    "        if not df_filtered.empty and \"traceback\" in df_filtered.columns:\n",
    "            print(f\"\\n=== First {limit_traceback_prints} Traceback(s) for exceptions matching: '{exception_filter}' ===\")\n",
    "            traceback_count = 0\n",
    "            for _, row in df_filtered.iterrows():\n",
    "                sweep_dir = row.get(\"sweep_dir\", \"?\")\n",
    "                trial = row.get(\"trial\", \"?\")\n",
    "                seed = row.get(\"seed\", \"?\")\n",
    "                tb = row[\"traceback\"]\n",
    "                print(f\"\\n--- Sweep Directory {sweep_dir} | Trial {trial} | Seed {seed} ---\\n\")\n",
    "                print(tb)\n",
    "                traceback_count += 1\n",
    "                if traceback_count >= limit_traceback_prints:\n",
    "                    break\n",
    "        else:\n",
    "            print(f\"\\n(No tracebacks found for exceptions matching: '{exception_filter}')\")\n",
    "    else:\n",
    "        print(\"No exceptions found ðŸŽ‰\")\n",
    "else:\n",
    "    print(\"'exception' column not found in df_trials.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated outcome statistics per parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stats to DataFrame for aggregation\n",
    "df_sweeps_outcomes = pd.concat([df_sweeps[param_cols], outcome_df], axis=1)\n",
    "df_sweeps_outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show aggregated statistics\n",
    "print(\"\\n=== Aggregated Outcome Statistics Across Sweeps ===\\n\")\n",
    "display(df_sweeps_outcomes.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mean outcome (relative) for each parameter value\n",
    "for param in param_cols:\n",
    "    print(f\"\\n=== Mean relative outcomes grouped by {param} ===\")\n",
    "    display(df_sweeps_outcomes.groupby(param)[outcome_df.columns].mean().round(5).astype(str) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot outcome distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df.sum().plot(kind=\"bar\")\n",
    "plt.title(\"Total outcome counts across all sweeps and trials\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all trials of given outcomes for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_to_trials = defaultdict(list)\n",
    "\n",
    "for _, row in df_trials.iterrows():\n",
    "    params = {k: row[k] for k in trial_param_cols}\n",
    "    for k, v in params.items():\n",
    "        if isinstance(v, str) and ((v.startswith(\"[\") and v.endswith(\"]\")) or (v.startswith(\"{\") and v.endswith(\"}\"))):\n",
    "            try:\n",
    "                params[k] = eval(v)\n",
    "            except Exception:\n",
    "                pass\n",
    "    entry = {\"sweep_params\": params, \"seed\": row[\"seed\"], \"sweep_dir\": row[\"sweep_dir\"]}\n",
    "    outcome_to_trials[row[\"outcome\"]].append(entry)\n",
    "\n",
    "# Example for the first appearing outcome\n",
    "first_outcome = next(iter(outcome_to_trials))\n",
    "print(f\"Example for outcome '{first_outcome}':\")\n",
    "for entry in outcome_to_trials[first_outcome][:5]:  # only show the first 5\n",
    "    print(entry)\n",
    "print(f\"Total: {len(outcome_to_trials[first_outcome])} trials with outcome '{first_outcome}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

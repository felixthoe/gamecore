{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc782819",
   "metadata": {},
   "source": [
    "# LQ Game: Basics\n",
    "\n",
    "### This notebook demonstrates how to build a 2-player LQ game from scratch with references to available factory methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f7c58",
   "metadata": {},
   "source": [
    "### 1. Imports\n",
    "To make the files in `src/` available to jupyter notebook, we have to add the root path of this directory to the Python path.  \n",
    "Furthermore, we use `%matplotlib` inline to ensure plots are displayed in the notebook, instead of additional windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Get the absolute root path of this repository\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "# Add it to the Python path\n",
    "if root_path not in sys.path:\n",
    "    sys.path.insert(0, root_path)\n",
    "\n",
    "from src.gamecore import (\n",
    "    LinearSystem,\n",
    "    QuadraticCost,\n",
    "    LinearStrategy,\n",
    "    LQPlayer,\n",
    "    LQGame,\n",
    "    SystemTrajectory,\n",
    "    feedback_nash_equilibrium\n",
    ")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8bd52",
   "metadata": {},
   "source": [
    "### 2. Define the system dynamics\n",
    "A linear system is defined by:\n",
    "- the state matrix A (shared among all players),\n",
    "- and one input matrix B_i per player.\n",
    " \n",
    "The constructor `LinearSystem` expects the input matrices to be given as a list:\n",
    "    Bs = [B_1, B_2, ..., B_N]\n",
    "\n",
    "This codebase uses the naming conventions:\n",
    "- a trailing 's' (like `Bs`, `costs`, `players`) indicates a list of objects of the respective singular form (`B`, `cost`, `player`).\n",
    "- a trailing '_i' (like `B_i`, `Q_i`, `R_i`) indicates an element of the player under consideration\n",
    "- a trailing '_j' or 'k' (like `B_j`, `Q_j`, `R_ijk`) corresponds to the *other* players from the perspective of player `i`\n",
    "- indices start at 0, so in general we have i, j, k in {0, 1, ..., N-1}\n",
    "\n",
    "**Tip**:  \n",
    "For convenience (or randomized experiments), you can use several factory methods to generate a system.\n",
    "Have a look at [src/utils/core_factories/system_factory.py](../../src/utils/core_factories/system_factory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 1], [-1, -0.5]])\n",
    "B0, B1 = np.array([[0], [1]]), np.array([[0], [0.5]])\n",
    "Bs = [B0, B1]\n",
    "\n",
    "system = LinearSystem(A=A, Bs=Bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5fe7b9",
   "metadata": {},
   "source": [
    "### 3. Define the cost functions\n",
    "Each player i seeks to minimize an infinite-horizon quadratic cost of the form:\n",
    "\n",
    "    J_i = ∫ [ xᵀ Q_i x + ∑_{j,k} u_jᵀ R_ijk u_k ] dt\n",
    "\n",
    "Here, Q_i penalizes state deviation, and R_ijk penalizes the control effort product of player j and k.  \n",
    "The R_ijk matrices are passed as a dictionary R_i = {(j,k): R_ijk}, where the keys start with a zero index.  \n",
    "The game constructor will later do some checks to ensure a positive definite R_iii, a positive semidefinite Q_i and in general symmetric matrices Q_i and R_ijj (whereas R_ijk for j!=k are unrestricted).\n",
    "\n",
    "**Tip**:  \n",
    "For convenience (or randomized experiments), you can use several factory methods to generate cost functions.\n",
    "Have a look at [src/utils/core_factories/cost_factory.py](../../src/utils/core_factories/cost_factory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q0 = np.eye(2)\n",
    "Q1 = np.diag([10.0, 1.0])\n",
    "\n",
    "R000 = 1.0 * np.eye(1)\n",
    "R011 = 0.1 * np.eye(1)\n",
    "R100 = 0.2 * np.eye(1)\n",
    "R111 = 1.0 * np.eye(1)\n",
    "\n",
    "R0 = {(0, 0): R000, (1, 1): R011}\n",
    "R1 = {(0, 0): R100, (1, 1): R111}\n",
    "\n",
    "cost0 = QuadraticCost(Q=Q0, R=R0)\n",
    "cost1 = QuadraticCost(Q=Q1, R=R1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bce48",
   "metadata": {},
   "source": [
    "## 4. Define policies for both players\n",
    "Each player’s strategy is a linear state-feedback controller:\n",
    "    u_i(t) = -K_i x(t)\n",
    "\n",
    "The gain matrix K_i is wrapped in a `LinearStrategy` object.\n",
    "\n",
    "**Tip**:  \n",
    "For convenience (or randomized experiments), you can use several factory methods to generate policies.\n",
    "Have a look at [src/utils/core_factories/strategy_factory.py](../../src/utils/core_factories/strategy_factory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = np.array([[1.0, 0.0]])\n",
    "K1 = np.array([[0.0, 1.0]])\n",
    "\n",
    "strategy0 = LinearStrategy(K=K0)\n",
    "strategy1 = LinearStrategy(K=K1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325e8d9",
   "metadata": {},
   "source": [
    "## 5. Create player objects\n",
    "Each player combines a strategy and a cost function. Furthermore, it tracks the strategies if the player adapts or learns in form of a `StrategyTrajectory`, initialized with the given strategy.   \n",
    "You can create players directly or use one of the factory methods in [src/utils/core_factories/player_factory.py](../../src/utils/core_factories/player_factory.py), which also handle the cost and strategy creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "player0 = LQPlayer(strategy=strategy0, cost=cost0, player_idx=0)\n",
    "player1 = LQPlayer(strategy=strategy1, cost=cost1, player_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f9833",
   "metadata": {},
   "source": [
    "## 6. Create the game\n",
    "The game couples the system dynamics with all player objects. Players are expected to be given as list. Supports continuous-time system dynamics (type=\"differential\") and discrete-time system dynamics (type=\"dynamic\").\n",
    "\n",
    "Of course, there are also factory methods for the game object, covering all previous steps: [src/utils/core_factories/game_factory.py](../../src/utils/core_factories/game_factory.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = LQGame(system=system, players=[player0, player1], type=\"differential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c999eae",
   "metadata": {},
   "source": [
    "## 7. Simulate the game from an initial state\n",
    "The game integrates the system forward in time using the strategies of the players.  \n",
    "Returns a [`SystemTrajectory`](../src/core/trajectory.py) object containing x(t), u(t), and list of cost values, which represent the total cost induced by these trajectories for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f917ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_player_costs(costs: list[float]):\n",
    "    \"\"\"\n",
    "    Print the cost for each player in the game.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"=== Costs of all players ===\")\n",
    "    for i, cost in enumerate(costs):\n",
    "        print(f\"Player {i} cost: {cost:.2f}\")\n",
    "\n",
    "def plot_system_trajectories(\n",
    "    traj: SystemTrajectory,\n",
    "    state_labels: list[str] = None,\n",
    "    control_labels: list[str] = None,\n",
    "    skip_plt_show: bool = False\n",
    ") -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plots the state and control trajectories of a simulated LQ game using matplotlib.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : Trajectory\n",
    "        Contains the time vector, state and control trajectories.\n",
    "    state_labels : list of str, optional\n",
    "        Labels for each state variable. If None, generic labels [\"x_0\", \"x_1\", ...] are used.\n",
    "    control_labels : list of str, optional\n",
    "        Labels for each control input. If None, generic labels [\"u_0\", \"u_1\", ...] are used.\n",
    "    skip_plt_show : bool, optional\n",
    "        Skips the plt.show() command at the end. Useful, if more figures are displayed after this function.\n",
    "        (Only the last plt.show() should be executed, otherwise the figures block each other)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[plt.Figure, plt.Axes]\n",
    "        The figure and axes objects containing the plots.\n",
    "    \"\"\"\n",
    "    t = traj.t\n",
    "    x, us = traj.x, traj.us\n",
    "\n",
    "    n = x.shape[1]\n",
    "    N = len(us)\n",
    "\n",
    "    if state_labels is None:\n",
    "        state_labels = [f\"$x_{{{i}}}$\" for i in range(n)]\n",
    "    if control_labels is None:\n",
    "        control_labels = [f\"$u_{{{i}}}$\" for i in range(N)]\n",
    "\n",
    "    # Plot setup\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    # --- State plot ---\n",
    "    for i in range(n):\n",
    "        axs[0].plot(t, x[:, i], label=state_labels[i], linewidth=2.5)\n",
    "    axs[0].set_title(\"State Trajectory\", fontsize=14)\n",
    "    axs[0].set_xlabel(\"Time\", fontsize=12)\n",
    "    axs[0].set_ylabel(\"State\", fontsize=12)\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend(fontsize=10)\n",
    "    axs[0].set_xlim([t[0], t[-1]])\n",
    "\n",
    "    # --- Control plot ---\n",
    "    for i, u_i in enumerate(us):\n",
    "        for j in range(u_i.shape[1]):\n",
    "            label = f\"{control_labels[i]}$_{{{j}}}$\" if u_i.shape[1] > 1 else control_labels[i]\n",
    "            axs[1].plot(t, u_i[:, j], label=label, linewidth=2.5)\n",
    "    axs[1].set_title(\"Control Inputs\", fontsize=14)\n",
    "    axs[1].set_xlabel(\"Time\", fontsize=12)\n",
    "    axs[1].set_ylabel(\"Input\", fontsize=12)\n",
    "    axs[1].grid(True)\n",
    "    axs[1].legend(fontsize=10)\n",
    "    axs[1].set_xlim([t[0], t[-1]])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if not skip_plt_show:\n",
    "        plt.show()\n",
    "    return fig, axs\n",
    "        \n",
    "x0 = np.array([1.0, 0.0])\n",
    "traj = game.simulate_system(x0, T=10.0)\n",
    "print_player_costs(traj.costs)\n",
    "fig, axs = plot_system_trajectories(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d039b",
   "metadata": {},
   "source": [
    "## 8. Lyapunov-based cost calculation\n",
    "In LQGames, we have the possibility to calculate an analytic cost value using the lyapunov matrix.  \n",
    "Note that they are different from the trajectory-based costs above and furthermore independent of the initial condition and numerical problems like, e.g., a simulation horizon chosen too short, which might goes unnoticed in experiments.  \n",
    "Hence, this cost should be preferred.\n",
    "\n",
    "Note: The Lyapunov-based cost is only defined for stable, linear time-invariant systems, whereas the trajectory-based cost is fully flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_player_costs(game.strategies_costs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed41a2",
   "metadata": {},
   "source": [
    "## 9. Nash Equilibrium\n",
    "The LQGame class features an implementation of \"Algorithm 6\" from Engwerda, \"Algorithms for computing Nash equilibria in deterministic LQ games\" to iteratively compute a Nash Equilibrium of the LQ Game, using the system dynamics and the cost functions.  \n",
    "Important to note are:\n",
    "- There my be an arbitrary number of equilibria in infinite horizon LQ Games, ranging from zero to infinity. If the algorithm converges, it only yields one and does not make any statement about its uniqueness.\n",
    "- As iterative algorithm, an initial set of policies is needed, which needs to yield a stable closed loop system. This set can be given as argument, otherwise the current policies of the players are used. Either way, the stability will be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_strategies = feedback_nash_equilibrium(game)\n",
    "game.adopt_strategies(nash_strategies)\n",
    "traj = game.simulate_system(x0, T=10)\n",
    "print_player_costs(game.strategies_costs())\n",
    "fig, axs = plot_system_trajectories(traj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
